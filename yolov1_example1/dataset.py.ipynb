{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOC数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class yoloDataset(data.Dataset):\n",
    "    image_size = 448\n",
    "    def __init__(self, root, list_file, train, transform):\n",
    "        self.root  = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.fnames = []\n",
    "        self.boxes  = []\n",
    "        self.labels = []\n",
    "        self.mean = (123, 117, 104) #RGB\n",
    "        \n",
    "        if isinstance(list_file, list):\n",
    "            tmp_file = '/tmp/listfile.txt'\n",
    "            os.system('cat %s > %s' % (' '.join(list_file), tmp_file))\n",
    "            list_file = tmp_file\n",
    "            \n",
    "        with open(list_file) as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        for line in lines:\n",
    "            splited = line.strip().split()\n",
    "            self.fnames.append(splited[0])\n",
    "            num_boxes = (len(splited) - 1) // 5\n",
    "            box = []\n",
    "            label = []\n",
    "            for i in range(num_boxes):\n",
    "                x = float(splited[1+5*i])\n",
    "                y = float(splited[2+5*i])\n",
    "                x2 = float(splited[3+5*i])\n",
    "                y2 = float(splited[4+5*i])\n",
    "                c = splited[5+5*i]\n",
    "                box.append([x,y,x2,y2])\n",
    "                label.append(int(c)+1)\n",
    "            self.boxes.append(torch.Tensor(box))\n",
    "            self.labels.append(torch.LongTensor(label))\n",
    "        self.num_samples = len(self.boxes)\n",
    "    def __getitem__(self, idx):\n",
    "        fname  = self.fnames[idx]\n",
    "        img    = cv2.imread(os.path.join(self.root+fname))\n",
    "        boxes  = self.boxes[idx].clone()\n",
    "        labels = self.labels[idx].clone()\n",
    "        if self.train:\n",
    "            img, boxes = self.random_flip(img, boxes)\n",
    "            img, boxes = self.randomScale(img, boxes)\n",
    "            img = self.randomBlur(img)\n",
    "            img = self.RandomBrightness(img)\n",
    "            img = self.RandomHue(img)\n",
    "            img = self.RandomSaturation(img)\n",
    "            img, boxes, labels = self.randomShift(img, boxes, labels)\n",
    "            img, boxes, labels = self.randomCrop(img, boxes, labels)\n",
    "        \n",
    "        h, w, _ = img.shape\n",
    "        boxes /= torch.Tensor([w,h,w,h]).expand_as(boxes)\n",
    "        img = self.BGR2RGB(img)\n",
    "        img = self.subMean(img, self.mean)\n",
    "        img = cv2.resize(img, (self.image_size, self.image_size))\n",
    "        target = self.encoder(boxes, labels) #7x7x30\n",
    "        for t in self.transform:\n",
    "            img = t(img)\n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def encoder(self, boxes, labels):\n",
    "        '''\n",
    "        Args:\n",
    "        - boxes: tensor,[[x1,y1,x2,y2],[]]\n",
    "                x1,y1,x2,y2都是相对于pic大小的归一化的值,即认为pic_size为单位1\n",
    "        - labels: tensor, [....]\n",
    "        Return:\n",
    "        - target: tensor of shape 7x7x30, \n",
    "                  channels:[box1,box2,prob]=[x,y,w,h,conf,x,y,w,h,conf,p(0),p(1),..,p(c-1)]\n",
    "            其中x,y是box中心点相对于grid左上角坐标的偏移量，并且归一化后的值（以grid大小为单位1进行归一化）\n",
    "            其中w,h是box宽和高相对于pic大小的归一化的值,,即认为pic_size为单位1\n",
    "        '''\n",
    "        grid_num = 7\n",
    "        target = torch.zeros((grid_num, grid_num, 30))\n",
    "        # cell_size也是相对于pic大小归一化后的值\n",
    "        cell_size = 1./grid_num\n",
    "        \n",
    "        # width=x2-x and height=y2-y\n",
    "        wh = boxes[:,2:] - boxes[:,:2]\n",
    "        # grid center:cx=(x2+x)/2 , cy=(y2+y)/2\n",
    "        cxcy = (boxes[:,2:] + boxes[:,:2]) / 2\n",
    "        \n",
    "        # 根据每个box所在的grid，设置对应grid\n",
    "        for i in range(cxcy.size()[0]):\n",
    "            cxcy_sample = cxcy[i]\n",
    "            ij = (cxcy_sample / cell_size).ceil() - 1\n",
    "            # box1's confidence\n",
    "            target[int(ij[1]), int(ij[0]), 4] = 1\n",
    "            # box2's confidence\n",
    "            target[int(ij[1]), int(ij[0]), 9] = 1\n",
    "            # classes probility\n",
    "            target[int(ij[1]), int(ij[0]), int(labels[i])+9] = 1\n",
    "            #\n",
    "            xy = ij*cell_size\n",
    "            delta_xy = (cxcy_sample - xy) / cell_size\n",
    "            target[int(ij[1]), int(ij[0]), 2:4] = wh[i]\n",
    "            target[int(ij[1]), int(ij[0]), :2] = delta_xy\n",
    "            target[int(ij[1]), int(ij[0]), 7:8] = wh[i]\n",
    "            target[int(ij[1]), int(ij[0]), 5:7] = delta_xy\n",
    "        return target\n",
    "    \n",
    "    def BGR2RGB(self, img):\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    def BGR2HSV(self, img):\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    def HSV2BGR(self, img):\n",
    "        return cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
